Ubiquitous Computing â€“ Dashboard Data Extraction
ğŸ“Œ About the Project

This project focuses on extracting key information from car dashboard images using image processing techniques in Python.
The system retrieves:

ğŸš— Speed
â›½ Fuel level
â± Time
ğŸ“ Distance travelled

âš™ï¸ Features

1) Speedometer Detection â†’ Detects needle position using edge detection and Hough Lines, maps it to calibrated speed.
2) Time & Distance Extraction â†’ Uses OCR (Tesseract) with preprocessing (grayscale, normalization, blur, ROI).
3) Fuel Gauge Detection â†’ Pixel counting after thresholding to calculate fuel percentage.
4) Database & Web Access â†’ Data stored in MongoDB and accessible via a hosted Glitch website.

ğŸ–¥ï¸ Image Processing Pipeline

ğŸ”¹ Speed Detection
- Convert image to grayscale
- Apply Gaussian blur
- Canny edge detection
- Detect lines with HoughLinesP
- Find longest line (needle)
- Calculate angle â†’ map to speed

ğŸ”¹ Time & Distance Extraction
- Grayscale conversion & normalization
- Gaussian blur + thresholding
- Define Region of Interest (ROI)
- OCR with Pytesseract
- Post-processing for valid formats

ğŸ”¹ Fuel Gauge Detection
- Grayscale + normalization
- Gaussian blur + thresholding
- ROI selection
- Pixel counting (cv2.countNonZero)
- Ratio â†’ fuel percentage
  
Input :
<img width="709" height="503" alt="image" src="https://github.com/user-attachments/assets/de5833dd-547b-4242-900a-058c448d1ebe" />

Output : 
<img width="792" height="437" alt="image" src="https://github.com/user-attachments/assets/fd556888-fbab-451f-a134-7897a57af7f7" />

